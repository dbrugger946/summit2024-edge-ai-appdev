{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20a0971",
   "metadata": {
    "id": "e20a0971"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8wM31kI5-PeJ",
   "metadata": {
    "id": "8wM31kI5-PeJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb58fc24",
   "metadata": {
    "id": "eb58fc24",
    "tags": []
   },
   "source": [
    "# Import pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717277b5",
   "metadata": {
    "id": "717277b5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_trained_model = tf.keras.applications.MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a6a8b-62fa-406a-a592-510e1e766106",
   "metadata": {
    "id": "717277b5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce1de34-75cf-44fb-9cac-b24f87380889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(pre_trained_model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc3b5cc-209a-44f3-929b-9be181ff6aa9",
   "metadata": {},
   "source": [
    "# Get Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287cd015-8381-411b-a458-286709edce99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LABELS_URL = 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'\n",
    "labels_path = tf.keras.utils.get_file('ImageNetLabels.txt', LABELS_URL)\n",
    "class_names = np.array(\n",
    "    open(labels_path).read().splitlines()\n",
    ")[1:]\n",
    "\n",
    "print('Labels shape:', class_names.shape)\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2a42f2-1279-4756-9b3b-9ff54b17e880",
   "metadata": {},
   "source": [
    "# Test single image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79af05df-88f6-49f1-85e9-d6b0c74d7ac8",
   "metadata": {},
   "source": [
    "## Load and preprocess image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b255cb-0510-46b0-a873-84c418229454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testfile = \"samples/banana.jpeg\"\n",
    "\n",
    "# Open image and format to RGB and size\n",
    "img = Image.open(testfile).convert('RGB')\n",
    "img = img.resize((224, 224), Image.LANCZOS)\n",
    "img = np.asarray(img)\n",
    "\n",
    "# Convert to Numpy\n",
    "mydata = np.empty((1, 224, 224, 3))\n",
    "mydata[0] = img\n",
    "\n",
    "# Convert from 0..255 values to -1..1 values\n",
    "ppdata = preprocess_input(mydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbb1d3e-f6b5-4c24-bf96-86a90dd61ce5",
   "metadata": {},
   "source": [
    "## Run Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614bf5a8-0718-4f40-bc25-882f7faf768f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "myprediction = pre_trained_model.predict(ppdata)\n",
    "\n",
    "print(myprediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3c4e3-ad63-4319-a41c-69cd3b8af02b",
   "metadata": {},
   "source": [
    "# Highest prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e8fb33-50e0-4bfd-8dfd-ed176e24ea54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.argmax(myprediction, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ff913-00e3-4395-b19b-739aa2d21880",
   "metadata": {},
   "source": [
    "# Prediction label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3715f33-28f0-4f82-96c9-74d62478f410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(class_names[np.argmax(myprediction, axis=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3949cce-82f0-461b-b835-c79cb6672ac7",
   "metadata": {},
   "source": [
    "# (slides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b387d1-2a17-49b8-b42c-1da50c6703c7",
   "metadata": {},
   "source": [
    "# Save Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047586cf-fe51-4890-b556-5270146b3525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We save the model in order to genereate a default signature we can later modify\n",
    "tf.saved_model.save(pre_trained_model, \"./../models/base/1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801da411-d7f2-4394-93e2-cb4e97802a69",
   "metadata": {},
   "source": [
    "# Save model with Base64 Signature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec77e99-4c19-4c51-8bc9-7f9ddd08bff9",
   "metadata": {},
   "source": [
    "### Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac7404-0aa1-4e61-928c-efee862219a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(class_names)\n",
    "labels = tf.constant([class_names])\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3219248-d436-42af-a996-387fd5bb1f83",
   "metadata": {},
   "source": [
    "### Load base model, add signature and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2d1e9a-3735-4578-8df8-8896781e3b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smodel = tf.saved_model.load(\"./../models/base/1\")\n",
    "\n",
    "# This is the current signature, that only accepts image tensors as input\n",
    "signature = smodel.signatures[\"serving_default\"]\n",
    "print(signature)\n",
    "\n",
    "# obtain the key name of the output (typically 'dense_X')\n",
    "keyOutput = next(iter(signature.structured_outputs))\n",
    "\n",
    "@tf.function()\n",
    "def my_predict(image_b64):\n",
    "\n",
    "    # get content\n",
    "    content = image_b64[0]\n",
    "    \n",
    "    # decode image    \n",
    "    image = tf.image.decode_jpeg(content,channels=3)\n",
    "    # tf.compat.v1.enable_eager_execution()\n",
    "    \n",
    "    # resize image\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    \n",
    "    # expand dimension to match signature\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    # set values in -1..1 range\n",
    "    image = preprocess_input(image)\n",
    "        \n",
    "    # execute prediction\n",
    "    prediction = signature(image)\n",
    "\n",
    "    # obtain index of maximum probability prediction\n",
    "    idx = tf.argmax(prediction[keyOutput],axis=1)\n",
    "    \n",
    "    # obtain the label for given index\n",
    "    label = tf.gather(labels, idx, batch_dims=1)\n",
    "\n",
    "    # obtain probability from Tensor\n",
    "    probability = prediction[keyOutput][0,idx[0]]\n",
    "    \n",
    "    # combine result in String Tensor format with [label,probability]\n",
    "    result = tf.concat([label, [tf.as_string(probability)]], axis=0)\n",
    "    \n",
    "    # return result_tensor\n",
    "    return result\n",
    "\n",
    "# Create new signature, to read b64 images\n",
    "new_signature = my_predict.get_concrete_function(\n",
    "    image_b64=tf.TensorSpec(name=\"image_b64\", shape=[1], dtype=tf.string)\n",
    ")\n",
    "\n",
    "# Save model with Base64 input signature\n",
    "tf.saved_model.save(\n",
    "    smodel,\n",
    "    export_dir=\"./../models/redbag/1\",\n",
    "    signatures=new_signature\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28f2fac-5d8e-40f6-a8cc-b53671c1e978",
   "metadata": {},
   "source": [
    "# Test Base64 Model with single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a9b5d9-3bfc-48e6-b13a-efd0df2a1040",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smodel = tf.saved_model.load(\"./../models/redbag/1\")\n",
    "\n",
    "# Load model's signature\n",
    "signature = smodel.signatures[\"serving_default\"]\n",
    "\n",
    "print(signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dbc0d5-70d9-4156-a6da-969a70a14aa4",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e34858-5b74-4528-b631-9c66d8cfef58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testfile = \"./samples/banana.jpeg\"\n",
    "\n",
    "# load test image\n",
    "content = tf.io.read_file(testfile)\n",
    "\n",
    "# reshape to signature's expected dimensions\n",
    "content = tf.reshape(content, shape = [1])\n",
    "\n",
    "# print(tf.print(content, summarize=3))\n",
    "\n",
    "# obtain signature\n",
    "f = smodel.signatures[\"serving_default\"]\n",
    "\n",
    "# run prediction\n",
    "myprediction = f(image_b64=content)\n",
    "print(myprediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c983c-e04a-4822-b259-7323be597cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Alpaca image classifier.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
